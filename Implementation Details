The project is implemented in a way that its get trained using ..... model using a data set and then the analysis is performed using live tweets which is achivwed with the help of twitter api which is achived with the help of tweepy module. Many such modules which are used here are tweepy, textblob, wordcloud, pandas, re, matplotlib. These modules provides us with several functions which helps us in making this sentiment analysis work efficiently and properly. First we create an api for twitter using tweepy by authorizing it with the twitter developer's credentials.Then after we extract the live tweets which from a particular user or a random hashtag and store it in a list. Now pandas is used for creating a dataframe from the previous tweets list. From here we take use of regular expression (re) module which is used to clean the tweets in the dataframe like removing stopwords, links, mentions and other things which dosen't make sense in sentiment analysis. Now we pass this dataframe to model which analyzes the tweets and provides us with the sentiment classification of it in possitive, negative and neutral. And parallely we make use of textblob which provides us with the subjectivity and polarity of the tweets for a more elaborative data on the tweets. Now after these steps we start analysing it through graphical/pictorial representations like implementing wordcloud from wordcloud module which creates a wordcloud of collection of words in the dataframe. For a more understanding of the sentiment we create a graoh of subjectivity vs polarity on the live tweets using matplotlib's pyplot function. And finally a simple representation of this sentiment analysis we plot a simple bar graph for sentiment vs count to show the count of all the 3 sentimental tweets.     
